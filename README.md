# Abel-RL: Reinforcement Learning for Symbolic Equation Solving

**Abel-RL** is a reinforcement learning (RL) framework designed for solving symbolic equations using RL agents.
The project integrates **Stable-Baselines3 (SB3)** and **custom environments** to explore algorithmic problem-solving.

## ğŸ“Œ Features
- Custom symbolic equation environments based on 
- Support for **PPO-Mask**, **DQN**, **A2C**, and intrinsic reward mechanisms
- Performance profiling and logging for easy debugging
- Multi-environment parallelization for efficient training

## ğŸš€ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/yourusername/abel-rl.git
cd abel-rl
pip install -r requirements.txt
```

## ğŸ“ Project Structure
```plaintext
abel-rl/
â”œâ”€â”€ backup/          # Old/unused files
â”œâ”€â”€ data/            # Checkpoints and trained models (ignored in Git)
â”œâ”€â”€ develop/         # Experimental scripts and rough work
â”œâ”€â”€ envs/            # Custom RL environments
â”œâ”€â”€ profiling/       # Profiling scripts
â”œâ”€â”€ tests/           # Unit tests
â”œâ”€â”€ training/        # Training scripts
â”œâ”€â”€ scripts/         # For running experiments
â”œâ”€â”€ utils/           # Helper functions
â”œâ”€â”€ .gitignore       # Ignore large/generated files
â”œâ”€â”€ LICENSE          # MIT License
â”œâ”€â”€ README.md        # Project documentation
â”œâ”€â”€ requirements.txt # Python dependencies
```

## ğŸ›  Usage

### **1ï¸âƒ£ Train a model**
Run the training script for solving a simple equation:

```bash
python training/train_single_eqn.py --agent_type ppo-mask --main_eqn "a*x+b"
```

### **2ï¸âƒ£ Evaluate a trained model**

```bash
python training/eval_model.py --agent_path data/a*x+b/ppo-mask_trained_model.zip
```

### **3ï¸âƒ£ Run performance profiling**

```bash
python profiling/profiler.py
```

## ğŸ“œ License
This project is licensed under the **MIT License** â€“ see [LICENSE](LICENSE) for details.

## ğŸ¤ Contributing
Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

---

Happy training! ğŸš€
